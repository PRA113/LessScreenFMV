# ‚ö†Ô∏è DEPRECATED - Hugging Face Models 

> **Hinweis:** Diese Dokumentation ist veraltet. Die App verwendet jetzt **OpenRouter** statt Hugging Face.  
> **Siehe:** [OPENROUTER_INTEGRATION.md](./OPENROUTER_INTEGRATION.md) f√ºr aktuelle Informationen.

## ‚ùå Warum nicht mehr Hugging Face?

Die Hugging Face Inference API hat sich als unzuverl√§ssig erwiesen:
- Alle getesteten Modelle gaben 404-Fehler zur√ºck
- Modelle sind h√§ufig nicht verf√ºgbar oder laden zu langsam
- Komplexe unterschiedliche Parameter je nach Modell

**Migration zu OpenRouter abgeschlossen am 23. Oktober 2025**

---

## Alte Dokumentation (nur zur Referenz)

~~Die LessScreen App nutzt die Hugging Face Inference API zur Generierung von Verst√§ndnisfragen basierend auf fotografierten Texten. Da die kostenlose API limitiert ist und Modelle sich √§ndern k√∂nnen, verwendet die App ein **Fallback-System** mit mehreren Modellen.~~

## Verwendete Modelle (aktualisiert)

Die folgenden Modelle werden nacheinander getestet, bis eines erfolgreich antwortet:

### 1. **mistralai/Mistral-7B-Instruct-v0.2**
- **Typ**: Instruction-tuned LLM
- **Gr√∂√üe**: 7B Parameter
- **Vorteile**: Sehr gute Qualit√§t, deutsch-f√§hig, stabil
- **Status**: ‚úÖ Empfohlen (Primary)

### 2. **google/flan-t5-base**
- **Typ**: Seq2Seq Modell
- **Gr√∂√üe**: 250M Parameter (klein & schnell)
- **Vorteile**: Schnell, zuverl√§ssig verf√ºgbar, mehrsprachig
- **Besonderheit**: Verwendet `max_length` statt `max_new_tokens`
- **Status**: ‚úÖ Empfohlen (Fallback)

### 3. **tiiuae/falcon-7b-instruct**
- **Typ**: Instruction-tuned LLM
- **Gr√∂√üe**: 7B Parameter
- **Vorteile**: Open-source, gute Performance
- **Status**: ‚ö†Ô∏è Backup (kann langsam laden)

### 4. **microsoft/DialoGPT-medium**
- **Typ**: Conversational Model
- **Gr√∂√üe**: 355M Parameter
- **Vorteile**: Konversationsf√§hig, kompakt
- **Besonderheit**: Prim√§r f√ºr Englisch, aber funktioniert mit einfachen Prompts
- **Status**: ‚ö†Ô∏è Emergency Fallback

## Removed Models (404 Errors)

Diese Modelle waren zuvor konfiguriert, sind aber nicht mehr √ºber die Inference API verf√ºgbar:

- ‚ùå `mistralai/Mistral-7B-Instruct-v0.3` ‚Üí Ersetzt durch v0.2
- ‚ùå `HuggingFaceH4/zephyr-7b-beta` ‚Üí Nicht mehr public
- ‚ùå `google/flan-t5-xxl` ‚Üí Zu gro√ü, nicht auf Inference API
- ‚ùå `google/flan-t5-large` ‚Üí Ebenfalls nicht verf√ºgbar

## Fallback-System

Falls **ALLE** Hugging Face Modelle fehlschlagen, generiert die App automatisch **lokale, regelbasierte Fragen**:

### Lokale Fallback-Fragen
Die `generateFallbackQuestions()` Funktion analysiert den erkannten Text und erstellt:

1. **Hauptthema-Frage**: Basierend auf dem ersten Satz + Schl√ºsselw√∂rtern
2. **Detail-Frage**: Basierend auf der Textmitte + Statistiken (Wort-/Satzanzahl)
3. **Schlussfolgerung-Frage**: Basierend auf dem letzten Satz oder Z√§hlfrage

**Vorteile**:
- ‚úÖ Funktioniert komplett offline (nach OCR)
- ‚úÖ Keine API-Kosten
- ‚úÖ Echte Antworten basierend auf dem Text
- ‚úÖ Eltern k√∂nnen Antworten ihrer Kinder √ºberpr√ºfen

**Beispiel**:
```javascript
// Text: "Der Wald ist voller Tiere. Dort leben Rehe, F√ºchse und V√∂gel..."

Frage 1: "Worum geht es in diesem Text?"
Antwort: "Der Text handelt von: Der Wald ist voller Tiere. Wichtige Begriffe sind: Tiere, leben, V√∂gel."

Frage 2: "Welche wichtigen Informationen werden genannt?"
Antwort: "Im Text steht: 'Dort leben Rehe, F√ºchse und V√∂gel'. Der Text enth√§lt insgesamt 42 W√∂rter und 4 S√§tze."

Frage 3: "Wie endet der Text?"
Antwort: "Am Ende hei√üt es: 'Alle Tiere leben friedlich zusammen.'"
```

## Prompt-Optimierung

Der Prompt wurde vereinfacht, um mit verschiedenen Modellen besser zu funktionieren:

```
Du bist ein Lehrer und erstellst Verst√§ndnisfragen auf Deutsch f√ºr Kinder (Grundschule, Schwierigkeit: mittel).

Text: "[Text hier]"

Aufgabe: Erstelle genau 3 Verst√§ndnisfragen mit Antworten zum Text. 
Antworte NUR mit einem JSON-Array, ohne weitere Erkl√§rungen.

Format:
[
  {"question": "Frage 1?", "answer": "Antwort 1."},
  {"question": "Frage 2?", "answer": "Antwort 2."},
  {"question": "Frage 3?", "answer": "Antwort 3."}
]

JSON-Antwort:
```

## Testing

Verwende die **HuggingFaceTest** Komponente in der App oder rufe direkt auf:

```bash
curl -X GET \
  https://[project-id].supabase.co/functions/v1/make-server-e4c1b088/test-hf \
  -H "Authorization: Bearer [anon-key]"
```

Die Test-Route pr√ºft alle 4 Modelle und gibt detaillierte Informationen zur√ºck.

## Rate Limits

- **5 Requests** pro Stunde pro Profil
- **20 Requests** pro Tag pro Profil
- Limits gelten f√ºr **erfolgreiche** Generierungen (nicht f√ºr Fallback)

## Fehlerbehandlung

Die App behandelt folgende Fehler gracefully:

- **404**: Model nicht gefunden ‚Üí N√§chstes Model probieren
- **503**: Model l√§dt noch ‚Üí 1 Sekunde warten, n√§chstes Model probieren
- **401/403**: API-Key Problem ‚Üí N√§chstes Model probieren
- **400**: Bad Request ‚Üí Parameter inkompatibel, n√§chstes Model probieren

Wenn alle Modelle fehlschlagen, wird der User informiert und Fallback-Fragen werden verwendet.

## Environment Variable

Ben√∂tigt:
```
HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxx
```

Kann erstellt werden auf: https://huggingface.co/settings/tokens

**Wichtig**: "Read" Berechtigung ist ausreichend f√ºr die Inference API.

## Kostenstruktur

- ‚úÖ Hugging Face Inference API: **KOSTENLOS** (mit Rate Limits)
- ‚úÖ Fallback-Fragen: **KOSTENLOS** (lokal generiert)
- ‚ö†Ô∏è Rate Limits verhindern Missbrauch
- üí° Perfekt f√ºr kostenloses Affiliate-Marketing finanziertes App

## Weiterentwicklung

M√∂gliche Verbesserungen:

1. **Caching**: Gleiche Texte nicht erneut verarbeiten
2. **User-Feedback**: Fragen bewerten lassen
3. **Custom Fine-Tuning**: Eigenes Modell f√ºr bessere Qualit√§t
4. **Paid API**: Falls App erfolgreich ist ‚Üí OpenAI API f√ºr Premium-User

## Support

Bei Problemen:
1. Check HuggingFaceTest Widget
2. Check Server Logs in Supabase
3. Verify API Key ist gesetzt
4. Fallback-Modus funktioniert immer!
